{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1: Imports #\n\nThis Python script is a concise utility designed to check and display the version of TensorFlow installed on your system. It accomplishes this by importing TensorFlow, along with a few standard Python libraries, and then prints the TensorFlow version to the console. \n\n**Libraries Imported:**\n\n* math: The math library provides mathematical functions and constants.\n\n* re: The re library allows for regular expression pattern matching.\n\n* os: The os library provides a way to interact with the operating system, including file and directory operations.\n\n* numpy (as np): The numpy library is used for numerical operations and handling arrays.\n\n* tensorflow (as tf): The tensorflow library is the main focus of this script and is used to check and print its version.","metadata":{}},{"cell_type":"code","source":"import math, re, os\nimport numpy as np\nimport tensorflow as tf\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:03:58.720801Z","iopub.execute_input":"2023-09-06T16:03:58.721086Z","iopub.status.idle":"2023-09-06T16:04:38.797466Z","shell.execute_reply.started":"2023-09-06T16:03:58.721060Z","shell.execute_reply":"2023-09-06T16:04:38.796612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Distribution Strategy #\n\nA TPU has eight different *cores* and each of these cores acts as its own accelerator. (A TPU is sort of like having eight GPUs in one machine.) We tell TensorFlow how to make use of all these cores at once through a **distribution strategy**. Run the following cell to create the distribution strategy that we'll later apply to our model.","metadata":{}},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:38.799090Z","iopub.execute_input":"2023-09-06T16:04:38.799571Z","iopub.status.idle":"2023-09-06T16:04:46.693009Z","shell.execute_reply.started":"2023-09-06T16:04:38.799542Z","shell.execute_reply":"2023-09-06T16:04:46.692003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll use the distribution strategy when we create our neural network model. Then, TensorFlow will distribute the training among the eight TPU cores by creating eight different *replicas* of the model, one for each core.\n\n# Step 3: Loading the Competition Data #\n\n## Get GCS Path ##\n\nWhen used with TPUs, datasets need to be stored in a [Google Cloud Storage bucket](https://cloud.google.com/storage/). You can use data from any public GCS bucket by giving its path just like you would data from `'/kaggle/input'`. The following will retrieve the GCS path for this competition's dataset.","metadata":{}},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\nprint(GCS_DS_PATH) # what do gcs paths look like?","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:46.694244Z","iopub.execute_input":"2023-09-06T16:04:46.694606Z","iopub.status.idle":"2023-09-06T16:04:46.705248Z","shell.execute_reply.started":"2023-09-06T16:04:46.694575Z","shell.execute_reply":"2023-09-06T16:04:46.704192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can use data from any public dataset here on Kaggle in just the same way. If you'd like to use data from one of your private datasets, see [here](https://www.kaggle.com/docs/tpu#tpu3pt5).\n\n## Load Data ##\n\nWhen used with TPUs, datasets are often serialized into [TFRecords](https://www.kaggle.com/ryanholbrook/tfrecords-basics). This is a format convenient for distributing data to each of the TPUs cores. We've hidden the cell that reads the TFRecords for our dataset since the process is a bit long. You could come back to it later for some guidance on using your own datasets with TPUs.","metadata":{}},{"cell_type":"code","source":"\nIMAGE_SIZE = [512, 512]\nGCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\nAUTO = tf.data.experimental.AUTOTUNE\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:46.707511Z","iopub.execute_input":"2023-09-06T16:04:46.707786Z","iopub.status.idle":"2023-09-06T16:04:46.763142Z","shell.execute_reply.started":"2023-09-06T16:04:46.707761Z","shell.execute_reply":"2023-09-06T16:04:46.762038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Data Pipelines ##\n\n### Overview:\nThe following Python code defines several utility functions for data preparation and augmentation in the context of TensorFlow. These functions are commonly used in machine learning tasks such as image classification. This documentation provides an explanation of each function, its purpose, and how it contributes to data processing in a machine learning pipeline.\n\n### Code Functions:\n\n#### 1. `data_augment(image, label)`\n- Purpose: This function performs data augmentation on an image.\n- Input:\n  - `image`: The input image (e.g., a training image).\n  - `label`: The corresponding label for the image.\n- Functionality:\n  - Randomly flips the input image horizontally (left to right).\n  - Can be extended to include other data augmentation techniques (e.g., random saturation adjustment).\n- Output:\n  - Returns the augmented image and the original label.\n\n#### 2. `get_training_dataset()`\n- Purpose: This function prepares a training dataset.\n- Functionality:\n  - Loads the training dataset from file(s) specified in `TRAINING_FILENAMES`.\n  - Applies data augmentation using the `data_augment` function.\n  - Repeats the dataset indefinitely to ensure it covers multiple epochs.\n  - Shuffles the dataset to introduce randomness.\n  - Batches the data to the desired batch size (`BATCH_SIZE`).\n  - Prefetches data for improved performance.\n- Output:\n  - Returns the prepared training dataset.\n\n#### 3. `get_validation_dataset(ordered=False)`\n- Purpose: This function prepares a validation dataset.\n- Input:\n  - `ordered` (Optional): If `True`, maintains the order of data elements (for validation).\n- Functionality:\n  - Loads the validation dataset from file(s) specified in `VALIDATION_FILENAMES`.\n  - Batches the data to the desired batch size (`BATCH_SIZE`).\n  - Caches the dataset in memory for faster access.\n  - Prefetches data for improved performance.\n- Output:\n  - Returns the prepared validation dataset.\n\n#### 4. `get_test_dataset(ordered=False)`\n- Purpose: This function prepares a test dataset.\n- Input:\n  - `ordered` (Optional): If `True`, maintains the order of data elements (for testing).\n- Functionality:\n  - Loads the test dataset from file(s) specified in `TEST_FILENAMES`.\n  - Batches the data to the desired batch size (`BATCH_SIZE`).\n  - Prefetches data for improved performance.\n- Output:\n  - Returns the prepared test dataset.\n\n#### 5. `count_data_items(filenames)`\n- Purpose: This function counts the number of data items in a list of TFRecord filenames.\n- Input:\n  - `filenames`: A list of TFRecord filenames.\n- Functionality:\n  - Extracts and sums the number of data items from the filenames (indicated by numeric values in the filenames).\n- Output:\n  - Returns the total count of data items in the provided filenames.\n\n#### Additional Information:\n- `NUM_TRAINING_IMAGES`, `NUM_VALIDATION_IMAGES`, and `NUM_TEST_IMAGES` are calculated using `count_data_items` for reporting purposes, indicating the number of data items in the respective datasets.\n\n### Important Notes:\n- These functions are designed to be used in a TensorFlow machine learning pipeline for tasks such as image classification.\n- Ensure that the constants (`TRAINING_FILENAMES`, `VALIDATION_FILENAMES`, `TEST_FILENAMES`, and `BATCH_SIZE`) are appropriately defined in your code.\n- Data augmentation techniques can be adjusted or extended in the `data_augment` function.\n- These functions facilitate efficient data loading and processing, improving the training and evaluation processes in machine learning models.\n\nFeel free to use and adapt these functions in your machine learning projects as needed.","metadata":{}},{"cell_type":"code","source":"\ndef data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec\n    # files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:46.764701Z","iopub.execute_input":"2023-09-06T16:04:46.765292Z","iopub.status.idle":"2023-09-06T16:04:46.780513Z","shell.execute_reply.started":"2023-09-06T16:04:46.765221Z","shell.execute_reply":"2023-09-06T16:04:46.779531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following Python code defines the batch size for distributed training and prepares three datasets: training, validation, and test datasets. It utilizes TensorFlow's tf.distribute.Strategy for distributing the training across multiple devices or replicas. This documentation provides an explanation of the code's purpose, how it sets the batch size, and how it creates and prints these datasets.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:46.781658Z","iopub.execute_input":"2023-09-06T16:04:46.781964Z","iopub.status.idle":"2023-09-06T16:04:47.219609Z","shell.execute_reply.started":"2023-09-06T16:04:46.781936Z","shell.execute_reply":"2023-09-06T16:04:47.218595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following Python code sets the NumPy print options and prints information about the shapes and labels of training data samples from a TensorFlow dataset. It is used for inspecting and understanding the structure of the training data. This documentation explains the purpose of the code and how it prints information about the training data.","metadata":{}},{"cell_type":"code","source":"np.set_printoptions(threshold=15, linewidth=80)\n\nprint(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:47.220788Z","iopub.execute_input":"2023-09-06T16:04:47.221198Z","iopub.status.idle":"2023-09-06T16:04:49.906187Z","shell.execute_reply.started":"2023-09-06T16:04:47.221155Z","shell.execute_reply":"2023-09-06T16:04:49.905060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following Python code prints information about the shapes and IDs of test data samples from a TensorFlow dataset. It is used for inspecting and understanding the structure of the test data. This documentation explains the purpose of the code and how it prints information about the test data.","metadata":{}},{"cell_type":"code","source":"print(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:49.907562Z","iopub.execute_input":"2023-09-06T16:04:49.907924Z","iopub.status.idle":"2023-09-06T16:04:50.674103Z","shell.execute_reply.started":"2023-09-06T16:04:49.907892Z","shell.execute_reply":"2023-09-06T16:04:50.672946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Explore Data #\n\n**Overview**:\nThe following Python code defines several functions to facilitate the display of images and training curves in machine learning projects. These functions are useful for visualizing data and training progress. This documentation explains the purpose of each function and how they can be used in your project.\n\n**Functions**:\n\n1. `batch_to_numpy_images_and_labels(data)`\n    - **Purpose**: Converts a batch of images and labels from TensorFlow tensors to NumPy arrays.\n    - **Input**:\n        - `data`: A batch of images and labels.\n    - **Functionality**:\n        - Extracts and converts images and labels to NumPy arrays.\n        - Handles special cases where labels may be binary strings (e.g., image IDs).\n    - **Output**:\n        - Returns NumPy arrays for images and labels.\n\n2. `title_from_label_and_target(label, correct_label)`\n    - **Purpose**: Generates a title for an image based on its label and whether the prediction is correct.\n    - **Input**:\n        - `label`: The actual label of the image.\n        - `correct_label`: The predicted label of the image (can be None for test data).\n    - **Functionality**:\n        - Constructs a title that includes the label and indicates whether the prediction is correct.\n    - **Output**:\n        - Returns a formatted title and a Boolean indicating correctness.\n\n3. `display_one_flower(image, title, subplot, red=False, titlesize=16)`\n    - **Purpose**: Displays a single image with an optional title.\n    - **Input**:\n        - `image`: The image to be displayed.\n        - `title`: The title to be displayed above the image.\n        - `subplot`: A tuple indicating the subplot configuration.\n        - `red` (Optional): If True, the title is displayed in red.\n        - `titlesize` (Optional): The font size for the title.\n    - **Functionality**:\n        - Displays the image with the specified title.\n        - Allows customization of title appearance.\n    - **Output**:\n        - Returns the updated subplot configuration.\n\n4. `display_batch_of_images(databatch, predictions=None)`\n    - **Purpose**: Displays a batch of images along with their labels or predictions.\n    - **Input**:\n        - `databatch`: A batch of images and labels.\n        - `predictions` (Optional): Predictions for the images (can be None for training).\n    - **Functionality**:\n        - Automatically determines the layout and size of subplots to accommodate all images.\n        - Displays images with labels or predicted labels.\n    - **Output**:\n        - Displays the batch of images with titles and optionally highlights incorrect predictions.\n\n5. `display_training_curves(training, validation, title, subplot)`\n    - **Purpose**: Plots training and validation curves for model performance.\n    - **Input**:\n        - `training`: Training data (e.g., accuracy or loss) to be plotted.\n        - `validation`: Validation data (e.g., accuracy or loss) to be plotted.\n        - `title`: Title of the plot.\n        - `subplot`: Subplot configuration for plotting.\n    - **Functionality**:\n        - Sets up subplots if necessary and plots training and validation curves.\n        - Adjusts subplot appearance and legend.\n    - **Output**:\n        - Displays the training and validation curves.\n\n**Important Notes**:\n- These functions are designed for visualizing data and monitoring the training process in machine learning projects.\n- The provided functions are versatile and can be adapted to various visualization requirements.\n- Ensure that you have the necessary libraries (e.g., Matplotlib) installed to use these functions effectively.\n- The code assumes that certain constants (e.g., CLASSES) and data structures are defined elsewhere in your project.\n- Use these functions as needed to gain insights into your data and model training progress.","metadata":{}},{"cell_type":"code","source":"\nfrom matplotlib import pyplot as plt\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case,\n                                     # these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is\n    # the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square\n    # or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n\n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:50.675470Z","iopub.execute_input":"2023-09-06T16:04:50.675795Z","iopub.status.idle":"2023-09-06T16:04:52.288588Z","shell.execute_reply.started":"2023-09-06T16:04:50.675766Z","shell.execute_reply":"2023-09-06T16:04:52.287478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In summary, this code essentially takes a TensorFlow dataset containing batches of training data, unstacks those batches into individual data samples, and then regroups them into new batches of 20 data samples each. The resulting iterator 'ds_iter' can be used to access and process these batches of training data one by one in your code.","metadata":{}},{"cell_type":"code","source":"ds_iter = iter(ds_train.unbatch().batch(20))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:52.292295Z","iopub.execute_input":"2023-09-06T16:04:52.292593Z","iopub.status.idle":"2023-09-06T16:04:52.329619Z","shell.execute_reply.started":"2023-09-06T16:04:52.292564Z","shell.execute_reply":"2023-09-06T16:04:52.328682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code sequentially fetches batches of training data from the iterator and displays them using the display_batch_of_images function, allowing you to inspect and visualize the training data during the development and debugging of your machine learning model.","metadata":{}},{"cell_type":"code","source":"one_batch = next(ds_iter)\ndisplay_batch_of_images(one_batch)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:52.330718Z","iopub.execute_input":"2023-09-06T16:04:52.331009Z","iopub.status.idle":"2023-09-06T16:04:57.249513Z","shell.execute_reply.started":"2023-09-06T16:04:52.330984Z","shell.execute_reply":"2023-09-06T16:04:57.248544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5: Define Model #\n\n","metadata":{}},{"cell_type":"markdown","source":"The provided code installs the efficientnet package using pip and then imports the EfficientNet model implementation from the efficientnet.tfkeras module. ","metadata":{}},{"cell_type":"code","source":"! pip install -q efficientnet\nimport efficientnet.tfkeras as efn","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:04:57.250628Z","iopub.execute_input":"2023-09-06T16:04:57.250916Z","iopub.status.idle":"2023-09-06T16:05:08.468710Z","shell.execute_reply.started":"2023-09-06T16:04:57.250890Z","shell.execute_reply":"2023-09-06T16:05:08.467511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code defines a deep learning model for a classification task using TensorFlow and the EfficientNetB7 architecture. Here's an explanation of what each part of the code does:\n\n1. `EPOCHS = 30`: This line sets the number of training epochs to 30. An epoch represents one complete iteration through the entire training dataset during training.\n\n2. `with strategy.scope():`: This line indicates that the subsequent code within the block will be executed within the context of a distribution strategy scope. Distribution strategies are used to train models on multiple GPUs or TPUs in a distributed manner.\n\n3. `pretrained_model = efn.EfficientNetB7(...)`: Inside the strategy scope, this line creates an instance of the EfficientNetB7 model from the `efficientnet.tfkeras` module. It is initialized with the following parameters:\n   - `weights='noisy-student'`: The model is initialized with weights pre-trained on the Noisy Student dataset. These pre-trained weights are often used as a starting point for transfer learning.\n   - `include_top=False`: The top classification layer of the pre-trained model is not included, allowing you to add your own classification layer.\n   - `input_shape=[*IMAGE_SIZE, 3]`: Specifies the expected input shape for images, where `IMAGE_SIZE` is assumed to be a tuple representing the image dimensions, and `3` represents the number of color channels (RGB).\n\n4. `pretrained_model.trainable = True`: This line sets the layers of the pre-trained model to be trainable, which means their weights can be updated during the fine-tuning process.\n\n5. `model = tf.keras.Sequential([...])`: This code defines the overall model architecture by creating a sequential model. It consists of:\n   - The `pretrained_model`: The EfficientNetB7 model as the base, which extracts features from input images.\n   - `tf.keras.layers.GlobalAveragePooling2D()`: A global average pooling layer, which reduces the spatial dimensions of the feature maps to a single value per feature map, effectively flattening the features.\n   - `tf.keras.layers.Dense(len(CLASSES), activation='softmax')`: The final classification layer with as many units as there are classes (defined by `len(CLASSES)`). The activation function is softmax, which is commonly used for multi-class classification tasks.\n\nIn summary, this code sets up a deep learning model using the EfficientNetB7 architecture, initializes it with pre-trained weights, and configures it for transfer learning. It is suitable for image classification tasks where you can fine-tune the pre-trained model's weights on your specific dataset.","metadata":{}},{"cell_type":"code","source":"EPOCHS = 30\n\nwith strategy.scope():\n    pretrained_model = efn.EfficientNetB7(\n        weights='noisy-student',\n        include_top=False ,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    pretrained_model.trainable = True\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n#         tf.keras.layers.Dense(64),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:05:08.469910Z","iopub.execute_input":"2023-09-06T16:05:08.470230Z","iopub.status.idle":"2023-09-06T16:06:15.311841Z","shell.execute_reply.started":"2023-09-06T16:05:08.470188Z","shell.execute_reply":"2023-09-06T16:06:15.310496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code compiles the deep learning model, specifying the optimizer, loss function, and evaluation metric. It also prints a summary of the model's architecture. Here's an explanation of each part of the code:\n\n1. `model.compile(...)`: This line compiles the model, configuring its training process. The `compile` method takes the following arguments:\n   - `optimizer='adam'`: Specifies the optimizer to be used during training. In this case, it uses the Adam optimizer, a popular choice for gradient-based optimization.\n   - `loss='sparse_categorical_crossentropy'`: Defines the loss function to be used for training. For multi-class classification tasks with integer labels (as opposed to one-hot encoded labels), 'sparse_categorical_crossentropy' is a common choice.\n   - `metrics=['sparse_categorical_accuracy']`: Specifies the evaluation metric(s) to be monitored during training. In this case, it uses 'sparse_categorical_accuracy' to measure the model's accuracy during training.\n\n2. `model.summary()`: This line prints a summary of the model's architecture, including the layers, output shape of each layer, and the number of trainable parameters. It provides a concise overview of the model's structure.\n\nIn summary, this code configures the model for training by specifying the optimizer, loss function, and evaluation metric. Additionally, it provides a summary of the model's architecture to help you understand its structure and parameter count.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:06:15.313319Z","iopub.execute_input":"2023-09-06T16:06:15.313661Z","iopub.status.idle":"2023-09-06T16:06:15.641597Z","shell.execute_reply.started":"2023-09-06T16:06:15.313631Z","shell.execute_reply":"2023-09-06T16:06:15.640213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6: Training #\n\n## Learning Rate Schedule ##\n\n**Overview**:\nThis Python code defines a learning rate schedule, specifically an exponential learning rate, for fine-tuning a deep learning model during training. Learning rate schedules help control the step size during gradient descent, influencing the convergence and performance of the model. This documentation explains the purpose of the code and its components.\n\n**Functions**:\n\n1. `exponential_lr(epoch, start_lr=**0.00001**, min_lr=**0.00001**, max_lr=**0.00005**, rampup_epochs=**5**, sustain_epochs=**0**, exp_decay=**0.8**) :\n    - **Purpose**: Generates a learning rate for a given epoch using an exponential decay schedule.\n    - **Input**:\n        - `epoch`: The current training epoch.\n        - `start_lr`: The initial learning rate.\n        - `min_lr`: The minimum learning rate.\n        - `max_lr`: The maximum learning rate.\n        - `rampup_epochs`: The number of epochs for a linear learning rate increase.\n        - `sustain_epochs`: The number of epochs with a sustained maximum learning rate.\n        - `exp_decay`: The exponential decay factor.\n    - **Functionality**:\n        - Computes the learning rate based on the given parameters and the current epoch.\n        - The learning rate schedule includes linear increase, sustained maximum, and exponential decay phases.\n    - **Output**:\n        - Returns the computed learning rate for the current epoch.\n\n2. `lr_callback`: This line creates a TensorFlow callback, `LearningRateScheduler`, that adjusts the learning rate during training according to the `exponential_lr` schedule. The callback is verbose, meaning it will print the learning rate adjustments during training.\n\n3. `rng = [i for i in range(EPOCHS)]`: Generates a list of epochs from 0 to `EPOCHS - 1`.\n\n4. `y = [exponential_lr(x) for x in rng]`: Computes the learning rates for each epoch in the range using the `exponential_lr` function.\n\n5. `plt.plot(rng, y)`: Plots the learning rate schedule to visualize how the learning rate changes over epochs.\n\n6. `print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(**y[0], max(y), y[-1]))`: Prints a summary of the learning rate schedule, showing the initial, maximum, and final learning rates.\n\n**Important Notes**:\n- The learning rate schedule is a critical hyperparameter in training deep learning models, affecting training convergence and performance.\n- The provided `exponential_lr` function allows you to customize the learning rate schedule based on your specific requirements.\n- Visualizing the learning rate schedule can help you understand how the learning rate evolves during training.","metadata":{}},{"cell_type":"code","source":"\n# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.8):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:06:15.643090Z","iopub.execute_input":"2023-09-06T16:06:15.643436Z","iopub.status.idle":"2023-09-06T16:06:15.974468Z","shell.execute_reply.started":"2023-09-06T16:06:15.643408Z","shell.execute_reply":"2023-09-06T16:06:15.973132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code defines and executes the training process for a deep learning model using TensorFlow. Here's an explanation of each part of the code:\n\n1. `EPOCHS = 30`: This line sets the number of training epochs to 30, which specifies how many times the entire training dataset will be used to update the model's weights during training.\n\n2. `STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE`: This line calculates the number of steps (batches) to complete one epoch of training. It divides the total number of training images (`NUM_TRAINING_IMAGES`) by the batch size (`BATCH_SIZE`). Each step processes a batch of training data.\n\n3. `history = model.fit(...)`: This line initiates the model training process using the `fit` method, which trains the model on the training data. It takes the following arguments:\n   - `ds_train`: The training dataset.\n   - `validation_data=ds_valid`: The validation dataset used to monitor the model's performance during training.\n   - `epochs=EPOCHS`: The number of training epochs.\n   - `steps_per_epoch=STEPS_PER_EPOCH`: The number of steps (batches) to complete one epoch.\n   - `callbacks=[lr_callback]`: A list of callbacks to be applied during training. In this case, it includes the learning rate scheduler (`lr_callback`) defined earlier.\n\nThis code will train the model for the specified number of epochs, updating its weights using gradient descent and monitoring its performance on the validation dataset. The training history, including loss and metrics, will be stored in the `history` variable for later analysis and visualization.","metadata":{}},{"cell_type":"code","source":"# Define training epochs\nEPOCHS = 30\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T16:06:15.975826Z","iopub.execute_input":"2023-09-06T16:06:15.976146Z","iopub.status.idle":"2023-09-06T17:15:43.067258Z","shell.execute_reply.started":"2023-09-06T16:06:15.976117Z","shell.execute_reply":"2023-09-06T17:15:43.065770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code calls the `display_training_curves` function to visualize the training and validation curves for loss and accuracy during the training of a deep learning model. Here's an explanation of each part of the code:\n\n1. `display_training_curves(...)`: This line calls the `display_training_curves` function twice to display two sets of training curves:\n   - The first call displays the training and validation loss curves.\n   - The second call displays the training and validation accuracy curves.\n\n2. `history.history['loss']`: This retrieves the training loss values from the training history. `history` is typically a dictionary that contains various metrics collected during training, and `'loss'` refers to the training loss.\n\n3. `history.history['val_loss']`: This retrieves the validation loss values from the training history. `'val_loss'` refers to the validation loss.\n\n4. `'loss'` and `'sparse_categorical_accuracy'`: These are used as labels for the curves to indicate whether you are plotting loss or accuracy curves.\n\n5. `211` and `212`: These are subplot configuration values that specify where to place the curves in the figure. The `211` indicates that the first set of curves (loss) will be placed in the top subplot, while the `212` indicates that the second set of curves (accuracy) will be placed in the bottom subplot.\n\nThe `display_training_curves` function is responsible for plotting the curves and formatting the subplots accordingly. It helps you visualize the model's training progress by showing how the loss and accuracy change over the training epochs.","metadata":{}},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:15:43.069893Z","iopub.execute_input":"2023-09-06T17:15:43.070319Z","iopub.status.idle":"2023-09-06T17:15:43.818993Z","shell.execute_reply.started":"2023-09-06T17:15:43.070285Z","shell.execute_reply":"2023-09-06T17:15:43.817730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7: Evaluate Predictions #\n\n","metadata":{}},{"cell_type":"markdown","source":"The provided code defines two functions for displaying a confusion matrix and training curves using Matplotlib. Here's an explanation of each function:\n\n**1. `display_confusion_matrix(cmat, score, precision, recall)`**:\n   - **Purpose**: This function displays a confusion matrix along with additional evaluation metrics such as F1 score, precision, and recall.\n   - **Inputs**:\n     - `cmat`: The confusion matrix.\n     - `score`: The F1 score.\n     - `precision`: The precision score.\n     - `recall`: The recall score.\n   - **Functionality**:\n     - Creates a Matplotlib figure and displays the confusion matrix as a heatmap.\n     - Labels the x and y axes with class names.\n     - If evaluation scores (F1, precision, recall) are provided, they are displayed as text on the plot.\n   - **Output**: The confusion matrix plot with evaluation metrics.\n\n**2. `display_training_curves(training, validation, title, subplot)`**:\n   - **Purpose**: This function displays training and validation curves (e.g., loss or accuracy) during the model training process.\n   - **Inputs**:\n     - `training`: The training data (e.g., loss or accuracy) to be plotted.\n     - `validation`: The validation data (e.g., loss or accuracy) to be plotted.\n     - `title`: The title of the plot.\n     - `subplot`: The subplot configuration for plotting.\n   - **Functionality**:\n     - Sets up subplots when called for the first time.\n     - Creates a plot with training and validation curves.\n     - Configures the appearance of the plot, including labels and legend.\n   - **Output**: The training and validation curves plot.\n\nThese functions are useful for visualizing model performance and understanding how the model evolves during training. The `display_confusion_matrix` function is particularly helpful for analyzing classification results, while `display_training_curves` helps monitor the training process by showing how metrics change over epochs.","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n    \ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:15:43.820429Z","iopub.execute_input":"2023-09-06T17:15:43.820781Z","iopub.status.idle":"2023-09-06T17:15:44.037391Z","shell.execute_reply.started":"2023-09-06T17:15:43.820752Z","shell.execute_reply":"2023-09-06T17:15:44.035895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix ##\n\n","metadata":{}},{"cell_type":"markdown","source":"The provided code computes a confusion matrix for a validation dataset and normalizes the matrix for better interpretation. Here's an explanation of each part of the code:\n\n1. `cmdataset = get_validation_dataset(ordered=True)`: This line loads the validation dataset using the `get_validation_dataset` function and sets the `ordered` parameter to `True`. An ordered dataset means that the order of elements is preserved, making it suitable for creating a confusion matrix.\n\n2. `images_ds = cmdataset.map(lambda image, label: image)`: This line extracts only the images from the validation dataset, creating a new dataset that contains only the images.\n\n3. `labels_ds = cmdataset.map(lambda image, label: label).unbatch()`: This line extracts the labels from the validation dataset and then unbatch them. Unbatching converts a batched dataset into an individual dataset with one element per example.\n\n4. `cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()`: This line retrieves the correct labels from the unbatched labels dataset. It uses `next(iter(...))` to obtain a batch of labels and then converts it to a NumPy array.\n\n5. `cm_probabilities = model.predict(images_ds)`: This line uses the trained model (`model`) to predict class probabilities for the images in the validation dataset (`images_ds`).\n\n6. `cm_predictions = np.argmax(cm_probabilities, axis=-1)`: This line computes the predicted class labels by taking the argmax of the predicted probabilities along the last axis. It determines the class with the highest probability for each image.\n\n7. `labels = range(len(CLASSES))`: This line creates a list of labels representing the class indices.\n\n8. `cmat = confusion_matrix(...)`: This line computes the confusion matrix using scikit-learn's `confusion_matrix` function. It takes the correct labels (`cm_correct_labels`) and predicted labels (`cm_predictions`) as inputs.\n\n9. `cmat = (cmat.T / cmat.sum(axis=1)).T`: This line normalizes the confusion matrix to show class-wise percentages of correct predictions. It divides each row (class) by the sum of that row to calculate the percentage of correct predictions.\n\nThe resulting `cmat` matrix represents the normalized confusion matrix, showing how well the model performs in classifying different classes in the validation dataset. It helps you understand where the model is making correct predictions and where it might be confused.","metadata":{}},{"cell_type":"code","source":"cmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalize","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:15:44.038849Z","iopub.execute_input":"2023-09-06T17:15:44.040281Z","iopub.status.idle":"2023-09-06T17:16:40.079956Z","shell.execute_reply.started":"2023-09-06T17:15:44.040246Z","shell.execute_reply":"2023-09-06T17:16:40.078492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the provided code, several evaluation metrics (F1 score, precision, recall) are computed based on the confusion matrix, and then the `display_confusion_matrix` function is called to display the confusion matrix with these metrics. Here's an explanation of each part of the code:\n\n1. `score = f1_score(...)`: This line computes the F1 score, which is a measure of a model's accuracy, based on the correct labels (`cm_correct_labels`) and predicted labels (`cm_predictions`). The `labels` parameter specifies the unique class labels, and `average='macro'` indicates that the F1 score should be computed for each class and then averaged to obtain a single score.\n\n2. `precision = precision_score(...)`: This line computes the precision score, which measures the accuracy of positive predictions, based on the correct labels (`cm_correct_labels`) and predicted labels (`cm_predictions`). Like the F1 score, it uses `labels` and `average='macro'` for calculation.\n\n3. `recall = recall_score(...)`: This line computes the recall score, which measures the model's ability to identify all relevant instances, based on the correct labels (`cm_correct_labels`) and predicted labels (`cm_predictions`). It also uses `labels` and `average='macro'` for calculation.\n\n4. `display_confusion_matrix(cmat, score, precision, recall)`: Finally, this line calls the `display_confusion_matrix` function to visualize the confusion matrix along with the computed F1 score, precision, and recall. These metrics provide a comprehensive view of the model's performance in classifying different classes in the validation dataset.\n\nThe `display_confusion_matrix` function was explained earlier and is used to create a visual representation of the confusion matrix with additional evaluation metrics displayed as text on the plot. This helps you assess the model's performance and identify areas where it may need improvement.","metadata":{}},{"cell_type":"code","source":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:16:40.081623Z","iopub.execute_input":"2023-09-06T17:16:40.081995Z","iopub.status.idle":"2023-09-06T17:16:43.869801Z","shell.execute_reply.started":"2023-09-06T17:16:40.081962Z","shell.execute_reply":"2023-09-06T17:16:43.868437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code processes a validation dataset by unbatching it, creating new batches with a batch size of 20, and then creating an iterator to iterate through these batches. Here's an explanation of each part of the code:\n\n1. `dataset = get_validation_dataset()`: This line obtains the validation dataset using the `get_validation_dataset` function. The dataset contains image-label pairs for validation.\n\n2. `dataset = dataset.unbatch().batch(20)`: Here, the validation dataset is first unbatched using the `unbatch` method. This step converts the dataset from batched form to individual examples. After unbatching, it is rebatched with a batch size of 20 using the `batch` method. This means that each batch will contain 20 examples.\n\n3. `batch = iter(dataset)`: This line creates an iterator (`batch`) to iterate through the batches of the validation dataset. The iterator allows you to access one batch at a time, making it convenient for processing and visualization.\n\nWith this setup, you can use the `batch` iterator to loop through batches of validation data, making it easy to perform operations or visualization tasks on each batch of examples in your validation dataset.","metadata":{}},{"cell_type":"code","source":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:16:43.871228Z","iopub.execute_input":"2023-09-06T17:16:43.872031Z","iopub.status.idle":"2023-09-06T17:16:43.960108Z","shell.execute_reply.started":"2023-09-06T17:16:43.871995Z","shell.execute_reply":"2023-09-06T17:16:43.958744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code extracts a batch of images and labels from the validation dataset, makes predictions using a trained model, and then displays the batch of images along with the predicted labels. Here's an explanation of each part of the code:\n\n1. `images, labels = next(batch)`: This line uses the `next` function to retrieve the next batch of data from the `batch` iterator. Specifically, it gets a batch of images and their corresponding labels from the validation dataset.\n\n2. `probabilities = model.predict(images)`: Here, the code uses the trained model (`model`) to predict class probabilities for the batch of images (`images`). The result is stored in the `probabilities` variable.\n\n3. `predictions = np.argmax(probabilities, axis=-1)`: This line calculates the predicted class labels by taking the argmax of the predicted probabilities along the last axis. It determines the class with the highest probability for each image in the batch and stores the predicted labels in the `predictions` variable.\n\n4. `display_batch_of_images((images, labels), predictions)`: Finally, this line calls the `display_batch_of_images` function to display the batch of images along with their true labels (`labels`) and predicted labels (`predictions`). This function was previously explained and is used for visualizing batches of images with labels and optionally highlighting incorrect predictions.\n\nWith these steps, you can visually inspect how the model is performing on a batch of validation data and compare the true labels with the model's predictions. This is a helpful way to gain insights into the model's performance and identify any potential issues or misclassifications.","metadata":{}},{"cell_type":"code","source":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:16:43.961394Z","iopub.execute_input":"2023-09-06T17:16:43.962018Z","iopub.status.idle":"2023-09-06T17:17:09.646773Z","shell.execute_reply.started":"2023-09-06T17:16:43.961986Z","shell.execute_reply":"2023-09-06T17:17:09.645222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8: Make Test Predictions #\n\nOnce you're satisfied with everything, you're ready to make predictions on the test set.\n\nIn the provided code, predictions are computed for a test dataset using a trained model. Here's an explanation of each part of the code:\n\n1. `test_ds = get_test_dataset(ordered=True)`: This line obtains the test dataset using the `get_test_dataset` function with the `ordered` parameter set to `True`. An ordered test dataset ensures that the order of elements is preserved, which is important for correctly matching predictions with test data.\n\n2. `print('Computing predictions...')`: This line prints a message indicating that predictions are about to be computed.\n\n3. `test_images_ds = test_ds.map(lambda image, idnum: image)`: Here, the code extracts only the images from the test dataset (`test_ds`) and creates a new dataset (`test_images_ds`) containing only the images. This step is necessary to make predictions on the test images.\n\n4. `probabilities = model.predict(test_images_ds)`: Using the trained model (`model`), this line predicts class probabilities for the test images contained in `test_images_ds`. The `probabilities` variable stores the predicted probabilities for each class for each test image.\n\n5. `predictions = np.argmax(probabilities, axis=-1)`: This line calculates the predicted class labels by taking the argmax of the predicted probabilities along the last axis. It determines the class with the highest probability for each test image and stores the predicted labels in the `predictions` variable.\n\n6. `print(predictions)`: Finally, the code prints the predicted labels for the test images. These predicted labels represent the model's classification for each test image.\n\nThis code snippet demonstrates how to use a trained model to make predictions on a test dataset, which is useful for evaluating the model's performance on unseen data or for generating predictions for tasks like image classification.","metadata":{}},{"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:17:09.648248Z","iopub.execute_input":"2023-09-06T17:17:09.648569Z","iopub.status.idle":"2023-09-06T17:18:10.291809Z","shell.execute_reply.started":"2023-09-06T17:17:09.648541Z","shell.execute_reply":"2023-09-06T17:18:10.290409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code generates a submission file in CSV format. Here's an explanation of each part of the code:\n\n1. `print('Generating submission.csv file...')`: This line prints a message to indicate that the code is about to generate the submission CSV file.\n\n2. `test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()`: This line extracts the image IDs from the test dataset (`test_ds`) by mapping a lambda function to extract the `idnum` field for each image. The result is unbatched to obtain individual image IDs.\n\n3. `test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')`: Here, the code retrieves the image IDs as a batch, converting them to NumPy arrays and then to Unicode strings. The image IDs represent the unique identifiers for the test images.\n\n4. Writing the Submission File:\n   - `np.rec.fromarrays([test_ids, predictions])`: This line creates a NumPy record array by combining the test image IDs and the corresponding model predictions.\n   - `fmt=['%s', '%d']`: Specifies the format for each column in the record array. `%s` is for strings (image IDs), and `%d` is for integers (class labels).\n   - `delimiter=','`: Specifies the delimiter (comma) to separate values in the CSV file.\n   - `header='id,label'`: Sets the header for the CSV file, indicating the columns (image ID and label).\n   - `comments=''`: Specifies that there should be no comments in the CSV file.\n\n5. `!head submission.csv`: Finally, this line uses the `head` command to display the first few lines of the generated submission CSV file in the console. This is a way to quickly inspect the contents of the file.\n\nThe resulting `submission.csv` file contains image IDs and corresponding model predictions, which can be submitted to a competition for evaluation.\n\n","metadata":{}},{"cell_type":"code","source":"print('Generating submission.csv file...')\n\n# Get image ids from test set and convert to unicode\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n\n# Write the submission file\nnp.savetxt(\n    'submission.csv',\n    np.rec.fromarrays([test_ids, predictions]),\n    fmt=['%s', '%d'],\n    delimiter=',',\n    header='id,label',\n    comments='',\n)\n\n# Look at the first few predictions\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:18:10.293376Z","iopub.execute_input":"2023-09-06T17:18:10.293856Z","iopub.status.idle":"2023-09-06T17:18:17.329642Z","shell.execute_reply.started":"2023-09-06T17:18:10.293820Z","shell.execute_reply":"2023-09-06T17:18:17.327893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9: Make a submission #\n\nIf you haven't already, create your own editable copy of this notebook by clicking on the **Copy and Edit** button in the top right corner. Then, submit to the competition by following these steps:\n\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n","metadata":{}}]}